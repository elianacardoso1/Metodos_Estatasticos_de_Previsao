---
title: "Trabalho Final ‚Äì M√©todos Estat√≠sticos de Previs√£o"
author: "Eliana Cardoso Gon√ßalves "
format: pdf
date: "2025-01-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)

library(zoo)
library(dplyr)
library(forecast)
library(kableExtra)
library(lmtest)
library(ggplot2)
library(gridExtra)
library(grid)  
library(car)
library(readr)
```

# DESCRI√á√ÉO DOS DADOS

```{r cars, echo=FALSE, message=FALSE, warning=FALSE}
setwd("C:/Users/eliana.cardoso/OneDrive - Funda√ß√£o Dom Cabral/Documentos/GitHub/mep")

dados_temperatura <- read_csv("daily-minimum-temperatures.csv")


colnames(dados_temperatura) <- c("data", "temperatura")

# S√©rie Mensal - Temperatura M√≠nima Mensal M√©dia
temperatura_mensal <- dados_temperatura %>%
  mutate(data = as.yearmon(data)) %>%
  filter(data >= as.yearmon("1982-01")) %>%
  group_by(data) %>%
  summarize(temperatura = mean(temperatura))

kable(head(temperatura_mensal)) %>%
  kable_styling("striped", full_width = F)
```

A s√©rie temporal escolhida para esta an√°lise √© referente √† temperatura m√≠nima di√°ria registrada na cidade de Melbourne, Austr√°lia, entre janeiro de 1982 e dezembro de 1990. Os dados foram retirados do reposit√≥rio Kaggle, especificamente do conjunto chamado Minimum Daily Temperatures in Melbourne, que pode ser acessado: https://www.kaggle.com/datasets/ingwangdk/minimum-daily-temperatures-in-melbourne-10-years/data?select=daily-minimum-temperatures.csv

A s√©rie original cont√©m dados di√°rios sobre a temperatura m√≠nima, mas, para facilitar a an√°lise de tend√™ncias ao longo do tempo e identificar padr√µes sazonais mais evidentes, decidimos transformar os dados para uma frequ√™ncia mensal. Para isso, calculamos a m√©dia mensal das temperaturas m√≠nimas, o que resultou em uma s√©rie de 108 observa√ß√µes mensais.

Essa transforma√ß√£o foi fundamental para que pud√©ssemos observar melhor as varia√ß√µes sazonais das temperaturas, como o comportamento t√≠pico das esta√ß√µes do ano. Com esses dados, √© poss√≠vel realizar an√°lises mais profundas sobre tend√™ncias clim√°ticas e at√© mesmo aplicar modelos estat√≠sticos para prever futuras varia√ß√µes, utilizando t√©cnicas como decomposi√ß√£o sazonal, suaviza√ß√£o exponencial e outros m√©todos de previs√£o de s√©ries temporais.

Foram retiradas as √∫ltimas 12 observa√ß√µes para o conjunto teste.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#*- Retirando as 12 ultimas observa√ß√µes para conjunto teste*

conjunto_treino <- temperatura_mensal[1:(nrow(temperatura_mensal) - 12), ]
conjunto_teste <- temperatura_mensal[(nrow(temperatura_mensal) - 11):nrow(temperatura_mensal), ]

#Grafico da serie utilizando conjunto de treino 
ggplot(conjunto_treino, aes(x = data, y = temperatura)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Temperatura M√≠nima Mensal M√©dia (1982-1990)", 
       x = "Data", 
       y = "Temperatura M√≠nima (¬∞C)") +
  theme_minimal() 
```

Ao analisar o gr√°fico da s√©rie temporal das temperaturas m√≠nimas mensais entre 1982 e 1990, √© poss√≠vel identificar algumas caracter√≠sticas importantes:

*Sazonalidade:* A s√©rie apresenta um comportamento sazonal claro, com varia√ß√µes regulares a cada 12 meses. Isso √© esperado devido √† transla√ß√£o da Terra em torno do Sol, que gera mudan√ßas de temperatura associadas √†s esta√ß√µes do ano.

*Estacionariedade:* Aparentemente as propriedades estat√≠sticas da s√©rie (como a m√©dia e a vari√¢ncia) permanecem constantes ao longo do tempo. Ou seja, a s√©rie n√£o aparenta ter tend√™ncia na parte simples nem sazonal, o que indica uma poss√≠vel estacionalidade.

# AJUSTE DE MODELOS - ARIMA

Para a identifica√ß√£o do melhor modelo, o primeiro passo foi analisar as caracter√≠sticas da s√©rie temporal em quest√£o. Para isso, foram utilizados os gr√°ficos ACF (Fun√ß√£o de Autocorrela√ß√£o) e PACF (Fun√ß√£o de Autocorrela√ß√£o Parcial), que s√£o ferramentas essenciais para verificar as depend√™ncias temporais da s√©rie.

O gr√°fico de ACF permite observar as correla√ß√µes entre os valores da s√©rie em diferentes defasagens (lags). A partir dessa an√°lise, foi poss√≠vel identificar se a s√©rie apresenta uma estrutura de depend√™ncia autoregressiva (AR) ou de m√©dia m√≥vel (MA), al√©m de indicar a necessidade de modelagem sazonal.

O gr√°fico de PACF, por sua vez, ajuda a identificar a ordem dos modelos autoregressivos, permitindo entender at√© que ponto os valores passados influenciam o valor presente da s√©rie. Com base nas observa√ß√µes dos gr√°ficos ACF e PACF, foi poss√≠vel fazer suposi√ß√µes iniciais sobre as ordens dos componentes AR e MA, tanto na parte sazonal quanto na parte n√£o sazonal.

Com as caracter√≠sticas da s√©rie identificadas, seguiu-se para a constru√ß√£o de modelos ARIMA com diferentes combina√ß√µes de ordens para os componentes AR, MA e sazonal. Para cada modelo ajustado, foi calculado o AIC (Crit√©rio de Informa√ß√£o de Akaike), com o objetivo de selecionar o modelo mais adequado, considerando a qualidade do ajuste e a complexidade do modelo. O modelo com o menor valor de AIC foi selecionado como o mais apropriado para a s√©rie temporal.

Em todos os testes estat√≠sticos realizados neste estudo, foi adotado um n√≠vel de signific√¢ncia de 5% (alpha; = 0,05).

```{r echo=FALSE, message=FALSE, warning=FALSE}
#passo 1)ACF e PACF para identificar depend√™ncias temporais
serie <- ts(conjunto_treino$temperatura, frequency = 12, start = c(1982, 1))

acf(serie, lag.max = 5*12, main = "Fun√ß√£o de Autocorrela√ß√£o (ACF) da S√©rie Temporal")
pacf(serie, lag.max = 5*12, main = "Fun√ß√£o de Autocorrela√ß√£o Parcial (PACF) da S√©rie Temporal")
```

Analisou-se as fun√ß√µes ACF e PACF para os 10 primeiros per√≠odos, e algumas caracter√≠sticas importantes foram observadas. Tanto no gr√°fico da Fun√ß√£o de Autocorrela√ß√£o, quanto no gr√°fico da Fun√ß√£o de Autocorrela√ß√£o Parcial temos um decrescimento exponencial que pode ser visualizado nos primeiros picos. Esse comportamento √© caracter√≠stico de um modelo ARMA(1,1), por isso ser√° o modelo inicial usado, para posteriormente sobrefix√°-lo.

Analisando os picos na componente sazonal, observamos que, na ACF, ocorre um decaimento exponencial. J√° na PACF, n√£o √© poss√≠vel identificar um pico claro no lag 12, embora esteja pr√≥ximo do limite. Com base nessa an√°lise, o modelo mais adequado parece ser um AR(1), que oferece o melhor ajuste aos dados.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Fun√ß√£o para exibir a tabela de coeficientes do modelo
exibir_coeficientes <- function(modelo) {
  # Resultados do teste de coeficientes
  coef_test <- coeftest(modelo)
  
  # Criando a tabela dos coeficientes
  coef_table <- data.frame(
    Estimativa = coef_test[, 1],
    Erro_Est = coef_test[, 2],
    Valor_z = coef_test[, 3],
    p_valor = coef_test[, 4]
  )
  
  # Exibindo a tabela com t√≠tulo
  library(knitr)
  kable(coef_table, 
        col.names = c( "Estimativa", "Erro Padr√£o", "Valor z", "p-valor"), 
        format = "markdown", 
        caption = "Resultado do Teste de Coeficientes do Modelo")
}

# Exemplo de uso da fun√ß√£o (substitua mod7 pelo seu modelo)
# Fun√ß√£o para exibir o AIC de um modelo
exibir_aic <- function(modelo) {
  # Calcular o valor do AIC para o modelo
  aic_value <- AIC(modelo)
  
  # Criar a tabela com o valor do AIC
  aic_table <- data.frame(
    Modelo = deparse(substitute(modelo)),  # Captura o nome do modelo
    AIC = aic_value
  )
  
  # Exibir a tabela com t√≠tulo
  library(knitr)
  kable(aic_table, 
        col.names = c("Modelo", "AIC"), 
        format = "markdown", 
        caption = paste("Valor do AIC para o Modelo", deparse(substitute(modelo))))
}




```

### Modelo 1

```{r echo=FALSE, message=FALSE, warning=FALSE}
mod1 <- arima(serie, order = c(1, 0, 1), seasonal = list(order = c(1, 0, 0)))


exibir_coeficientes(mod1)
exibir_aic(mod1)
```

O Modelo com nossa hip√≥tese inical, o par√¢metro da media m√≥vel n√£o foi significativo com isso tiramos esse coeficiente.



## Sobrefixa√ß√£o da parte simples
### Modelo 2

```{r echo=FALSE}
mod2 <- arima(serie, order = c(1, 0, 0), seasonal = list(order = c(1, 0, 0)))
exibir_coeficientes(mod2)
exibir_aic(mod2)
```

Assim concluirmos que o modelo 2, sem ma1 ficou melhor ajustado, uma vez que possui um bom AIC (341.5836) e todos componentes significativos.

Ao analisar $\theta$ e $\phi$, comprovamos a inversibilidade e estacionariedade, uma vez que ambos s√£o menores do que 1.

## Sobrefixa√ß√£o da sazonalidade

Modelo 3

```{r}
mod3 <- arima(serie, order = c(1, 0, 0), seasonal = list(order = c(2, 0, 0)))

exibir_coeficientes(mod3)

exibir_aic(mod3)
```

Adicionando um novo parametro na parte sazonal referente a parte autorregressiva. Obtivemos um todos os coeficientes significativos. E um AIC menor em rela√ß√£o ao encontrado no modelo 2. Ao analisar $\theta$ e $\phi$, comprovamos a inversibilidade e estacionariedade, uma vez que ambos s√£o menores do que 1.

### Modelo 4

```{r}
mod4 <- arima(serie, order = c(1, 0, 0), seasonal = list(order = c(1, 0, 1)))

exibir_coeficientes(mod4)

exibir_aic(mod4)
```

Se o modelo 4 apresenta um ùúô muito pr√≥ximo de 1, podemos rejeit√°-lo como estacion√°rio, mesmo com um AIC menor. O modelo 3, embora tenha um AIC um pouco maior, √© estacion√°rio e mais confi√°vel do ponto de vista te√≥rico e estat√≠stico.

## An√°lise residuos:

```{r echo=FALSE, message=FALSE, warning=FALSE}

conjunto_treino_residuos <- conjunto_treino %>%
  mutate(
    Res√≠duos_M3 = mod3$residuals
  )

## Plot dos res√≠duos do Modelo 9
plot_residuos_M3 <- conjunto_treino_residuos %>%
  ggplot() +
  geom_line(aes(x = data, y = Res√≠duos_M3, color = "M3")) +
  labs(x = 'Tempo', y = 'Res√≠duos', color = 'Modelo') +
  ggtitle('Res√≠duos - Modelo M3') +
  theme_minimal()

grid.arrange(plot_residuos_M3)
```

O pressuposto da vari√¢ncia constante ao longo do tempo foi atendido, garantindo que os res√≠duos do modelo n√£o apresentam padr√µes sistem√°ticos ou mudan√ßas na dispers√£o.

```{r}
# Analise normalidade dos residuos:
# Resultados do teste de normalidade Shapiro-Wilk
shapiro_test <- shapiro.test(mod3$residuals)

# Exibir os resultados em uma tabela usando kable com t√≠tulo
resultados <- data.frame(
  Estat√≠stica = shapiro_test$statistic,
  `Valor p` = shapiro_test$p.value
)


# Exibindo a tabela com t√≠tulo
kable(resultados, 
      col.names = c("Estat√≠stica de Teste", "Valor p"), 
      format = "markdown", 
      caption = "Resultado do Teste de Normalidade de Shapiro-Wilk para os Res√≠duos do Modelo")

```

No teste de Shapiro-Wilk, nossa hip√≥tese nula √© a de os dados seguem a distribui√ß√£o normal. O p-valor do teste foi igual a 0.5307165. Utilizando o n√≠vel de signific√¢ncia de 5%, n√£o rejeitaremos a hip√≥tese nula. Logo, o pressuposto de normalidade tamb√©m foi atendido.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# ACF e PACF para o modelo M7
acf_plot_M7 <- ggAcf(mod3$residuals, lag.max =5*12) +
  ggtitle("ACF - Modelo M3") +
  theme_minimal()

pacf_plot_M7 <- ggPacf(mod3$residuals, lag.max = 5*12) +
  ggtitle("PACF - Modelo M3") +
  theme_minimal()

# Teste de Box-Pierce
box_test_M7_1 <- Box.test(mod3$residuals, lag = 1, type = "Ljung-Box", fitdf = 0)
box_test_M7_2 <- Box.test(mod3$residuals, lag = 2, type = "Ljung-Box", fitdf = 0)
box_test_M7_11 <- Box.test(mod3$residuals, lag = 11, type = "Ljung-Box", fitdf = 0)
box_test_M7_12 <- Box.test(mod3$residuals, lag = 12, type = "Ljung-Box", fitdf = 0)
box_test_M7_24 <- Box.test(mod3$residuals, lag = 24, type = "Ljung-Box", fitdf = 0)

p_value_box_test_M7_1 <- box_test_M7_1$p.value
p_value_box_test_M7_2 <- box_test_M7_2$p.value
p_value_box_test_M7_11 <- box_test_M7_11$p.value
p_value_box_test_M7_12 <- box_test_M7_12$p.value
p_value_box_test_M7_24 <- box_test_M7_24$p.value

tabela_pvalores <- data.frame(
  Lag = c("1", "2", "11", "12", "24"),
  P_valor = c(p_value_box_test_M7_1, p_value_box_test_M7_2, p_value_box_test_M7_11, p_value_box_test_M7_12, p_value_box_test_M7_24)) %>% 
  kable(col.names = c("Lag", "P-valor"), caption = "P-valores do Teste de Box-Pierce para os Lags determinados") %>%
  kable_styling("striped", full_width = F)

# Plot ACF e PACF lado a lado com p-valor do Box-Test
grid.arrange(
  acf_plot_M7, pacf_plot_M7,
  ncol = 2
)
```



Em rela√ß√£o aos gr√°ficos dos res√≠duos, a fun√ß√£o de autocorrela√ß√£o (ACF) apresenta cinco picos significativos, indicando poss√≠veis autocorrela√ß√µes nos primeiros lags. Por outro lado, a fun√ß√£o de autocorrela√ß√£o parcial (PACF) revelou um pico significativo, indicando que o valor atual est√° fortemente relacionado ao valor imediatamente anterior.

A an√°lise da autocorrela√ß√£o dos res√≠duos √© essencial para verificar se o modelo ajustado ARIMA capturou adequadamente as depend√™ncias temporais da s√©rie. Se houver autocorrela√ß√£o significativa nos res√≠duos, isso indica que o modelo n√£o est√° ajustado corretamente.No teste de Box-Ljung, a hip√≥tese nula √© de que n√£o existe autocorrela√ß√£o significativa nos res√≠duos, ou seja, os res√≠duos s√£o independentes. O p-valor obtido no teste para o primeiro lag foi de 0.1551, o que indica que, para este lag espec√≠fico, n√£o podemos rejeitar a hip√≥tese nula, sugerindo aus√™ncia de autocorrela√ß√£o significativa. Isso indica que o modelo ARIMA ajustado (mod3) n√£o conseguiu explicar completamente as depend√™ncias temporais presentes na s√©rie

No entanto, para os lags 2, 11, 12 e 24, os p-valores foram menores que 0,05 (0.009315, 0.001525, 0.0004527 e 4.154e-06, respectivamente), indicando que nesses lags h√° evid√™ncias de autocorrela√ß√£o significativa nos res√≠duos, e a hip√≥tese nula de independ√™ncia deve ser rejeitada.

Portanto, os res√≠duos apresentam correla√ß√£o significativa em determinados lags, sugerindo que o modelo ajustado pode n√£o ter capturado completamente todas as depend√™ncias temporais nos dados. Nesse caso, outro modelo, que n√£o faz parte do grupo dos ARIMAs estudados na disciplina, poderia ser ajustado aos dados. N√£o tendo as ferramentas para tal, consideraremos o modelo 7 aquele com melhor ajuste entre os analisados."

# AJUSTE DE MODELOS - Alisamento Exponencial

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Decompondo a s√©rie temporal (aditiva)
decomposicao_aditiva <- decompose(serie, type = "additive")
plot(decomposicao_aditiva)

# Decompondo a s√©rie temporal (multiplicativa)
decomposicao_multiplicativa <- decompose(serie, type = "multiplicative")
plot(decomposicao_multiplicativa)
```

Os plots acima decomp√µe a s√©rie temporal em tr√™s componentes principais: tend√™ncia, sazonalidade e res√≠duo:

*Tend√™ncia:* A s√©rie parece mostrar um aumento nas temperaturas m√≠nimas a partir de 1987, sugerindo uma tend√™ncia de aquecimento nas √∫ltimas d√©cadas do per√≠odo analisado. No entanto, √© importante realizar testes estat√≠sticos.

*Sazonalidade:* A sazonalidade √© claramente vis√≠vel, com picos e vales que se repetem a cada 12 meses. Isso reflete as varia√ß√µes t√≠picas de temperatura associadas √†s esta√ß√µes do ano, com temperaturas mais altas no ver√£o e mais baixas no inverno.

*Res√≠duo:* O res√≠duo apresenta um padr√£o aleat√≥rio, com valores positivos e negativos distribu√≠dos de forma equilibrada. Isso sugere que o modelo de decomposi√ß√£o conseguiu capturar a maior parte da variabilidade da s√©rie, deixando apenas flutua√ß√µes aleat√≥rias, ou seja, o modelo foi bem-sucedido em explicar os principais componentes da s√©rie.

Para determinar qual modelo de decomposi√ß√£o (aditivo ou multiplicativo) √© mais adequado, √© necess√°rio realizar alguns testes e an√°lises adicionais:

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Holt-Winters Aditivo
aehw.aditivo <- HoltWinters(serie, alpha = NULL, beta = NULL, gamma = NULL, seasonal = c("additive"))

# Extraindo o erro quadr√°tico m√©dio (RMSE), AIC e SSE
RMSE <- sqrt(aehw.aditivo$SSE / length(serie))
SSE <- aehw.aditivo$SSE

# Extraindo os par√¢metros do modelo aditivo
parametros_aditivo <- data.frame(
  "Par√¢metro" = c("Alpha", "Beta", "Gamma", "RMSE", "SSE"),
  "Valor" = c(aehw.aditivo$alpha, aehw.aditivo$beta, aehw.aditivo$gamma, 
              RMSE, SSE)
)

# Exibindo os par√¢metros do modelo aditivo em formato de tabela
kable(parametros_aditivo, caption = "Par√¢metros e M√©tricas do Modelo Aditivo de Holt-Winters") %>% 
  kable_styling(full_width = F, position = "center")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Holt-Winters Multiplicativo
aehw.multiplicativo <- HoltWinters(serie, alpha = NULL, beta = NULL, gamma = NULL, seasonal = c("multiplicative"))

# Extraindo o erro quadr√°tico m√©dio (RMSE), AIC e SSE
RMSE_multiplicativo <- sqrt(aehw.multiplicativo$SSE / length(serie))
SSE_multiplicativo <- aehw.multiplicativo$SSE

# Extraindo os par√¢metros do modelo multiplicativo
parametros_multiplicativo <- data.frame(
  "Par√¢metro" = c("Alpha", "Beta", "Gamma", "RMSE", "SSE"),
  "Valor" = c(aehw.multiplicativo$alpha, aehw.multiplicativo$beta, aehw.multiplicativo$gamma, 
              RMSE_multiplicativo, SSE_multiplicativo)
)

# Exibindo os par√¢metros do modelo multiplicativo em formato de tabela
kable(parametros_multiplicativo, caption = "Par√¢metros e M√©tricas do Modelo Multiplicativo de Holt-Winters") %>% 
  kable_styling(full_width = F, position = "center")
```

-   RMSE (Root Mean Squared Error): Mede a precis√£o do modelo. Quanto menor, melhor o modelo ajusta-se aos dados.
-   SSE (Soma dos Erros ao Quadrado): Mede a soma dos quadrados dos res√≠duos (erros), sendo uma indica√ß√£o do qu√£o bem o modelo est√° ajustado.

O modelo aditivo apresenta um alpha de 0.2278, o que indica uma suaviza√ß√£o moderada da s√©rie temporal, ou seja, o modelo atribui um peso razo√°vel aos valores mais recentes sem exagerar. O beta de 0.0169 sugere uma tend√™ncia de crescimento ou decrescimento muito suave, enquanto o gamma de 0.5370 aponta para uma sazonalidade com um impacto consider√°vel na modelagem. A RMSE de 0.9957 e o SSE de 95.1901 s√£o relativamente baixos, sugerindo que o modelo aditivo consegue capturar bem a variabilidade dos dados e ajustar-se de forma eficaz √† s√©rie.

Por outro lado, o modelo multiplicativo apresenta um alpha um pouco maior (0.2870), o que indica que ele atribui um peso ligeiramente maior aos dados mais recentes, ajustando-se mais rapidamente a mudan√ßas nas observa√ß√µes. O beta de 0.0074 √© bem baixo, o que significa que a tend√™ncia do modelo √© muito suave, com uma varia√ß√£o muito pequena. O gamma de 0.6553, por sua vez, sugere uma sazonalidade mais forte, ou seja, o modelo multiplicativo ajusta-se a varia√ß√µes sazonais mais acentuadas. No entanto, a RMSE de 1.0741 e o SSE de 110.7444 s√£o maiores, indicando que o modelo multiplicativo tem um desempenho inferior, com maior erro de ajuste e menor precis√£o.

Dado que o modelo aditivo apresenta valores de RMSE e SSE menores, indicando um ajuste mais preciso e menos erro, ele ser√° o modelo escolhido para esta s√©rie temporal.

## Previs√µes usando AEHW aditivo

```{r}
previsao_alisamento <- predict(aehw.aditivo, n.ahead = 11, prediction.interval = T,
level = 0.95, interval = "prediction")
a <- ts(conjunto_teste$temperatura, frequency = 12, start = 1990)
plot(aehw.aditivo, previsao_alisamento , lwd =2, col = "black", xlab = "Ano", ylim = c(0,20)); lines(a, col = "black", lwd = 1)
```

## Previs√£o do modelo ARIMA

```{r}
n=length(serie)
H=12

require(forecast)
previsao_arima=forecast(serie, 12, level=c(95))

```

```{r}
# Grafico da serie com previsoes e intervalos de previsao
Dados=c(serie,rep(NA,12))
CEPPrev=ts(Dados,start=1982,frequency=12)
previsao <- ts(rep(NA,n+12),start=1982,frequency=12)
LI <- ts(rep(NA,n+12),start=1982,frequency=12)
LS <- ts(rep(NA,n+12),start=1982,frequency=12)
for(i in 1:H){
previsao[n+12-H+i] <- previsao_arima$mean[i]
LI[n+12-H+i] <-previsao_arima$lower[i]
LS[n+12-H+i] <- previsao_arima$upper[i]
}
plot(CEPPrev,type='l',xlab='Ano',ylab='CEP',ylim=c(0,40))
lines(previsao, col='blue')
lines(LI, col='red')
lines(LS, col='red')

```

# COMPARA√á√ÉO DOS MODELOS

```{r}
# Valores reais do conjunto de teste
valores_reais <- conjunto_teste$temperatura

 previsao_alisamento= data.frame( previsao_alisamento)

# Erros para ARIMA
mae_arima <- mean(abs(valores_reais - previsao_arima$mean))
rmse_arima <- sqrt(mean((valores_reais - previsao_arima$mean)^2))
mape_arima <- mean(abs((valores_reais - previsao_arima$mean) / valores_reais)) * 100

# Erros para Alisamento Exponencial
mae_alisamento <- mean(abs(valores_reais - previsao_alisamento$fit ))
rmse_alisamento <- sqrt(mean((valores_reais - previsao_alisamento$fit )^2))
mape_alisamento <- mean(abs((valores_reais -  previsao_alisamento$fit) / valores_reais)) * 100

```

```{r}
# Organizando os resultados em uma tabela
resultados <- data.frame(
  Modelo = c("ARIMA", "Alisamento Exponencial"),
  MAE = c(mae_arima, mae_alisamento),
  RMSE = c(rmse_arima, rmse_alisamento),
  MAPE = c(mape_arima, mape_alisamento)
)

# Exibindo os resultados
kable(resultados)

```

Com base nos resultados das m√©tricas de erro, o modelo de Alisamento Exponencial apresentou um desempenho superior ao ARIMA. Ele obteve valores menores de MAE (0.6323 contra 0.6662), RMSE (0.7858 contra 0.8713) e MAPE (5.8277 contra 6.0883). Essas diferen√ßas indicam que o Alisamento Exponencial foi mais eficaz em reduzir os erros absolutos e percentuais, al√©m de lidar melhor com varia√ß√µes maiores nos dados.

Portanto, para o conjunto de dados testado, o Alisamento Exponencial se mostra uma escolha mais adequada, oferecendo previs√µes mais precisas. Ele √© particularmente vantajoso para cen√°rios em que erros percentuais e grandes desvios devem ser minimizados, garantindo maior confiabilidade nas estimativas realizadas.
